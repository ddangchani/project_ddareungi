{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Xbo7I84YdWxO"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","\n","np.random.seed(40)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZM4Uc_pbdWxQ"},"outputs":[],"source":["# Data Load\n","df_train = pd.read_csv('train.csv')\n","df_train = df_train.iloc[:,1:]\n","df_train.columns = ['hour', 'temp', 'precip',\n","       'windspeed', 'humidity', 'visibility',\n","       'ozone', 'pm10', 'pm2_5', 'count']\n","df_X = df_train[df_train.columns.drop('count')]\n","df_y = df_train['count'].values\n","\n","X_train, X_val, y_train, y_val = train_test_split(df_X, df_y, test_size=0.3, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYoD7463dWxR"},"outputs":[],"source":["# # Visualize Pipeline\n","from sklearn import set_config\n","\n","set_config(display=\"diagram\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-5912-ddWxS"},"outputs":[],"source":["# Data Preprocessing\n","numeric_features = list(df_X.columns.drop(['precip','hour']))\n","numeric_transformer = Pipeline(\n","    steps=[(\"imputer\",SimpleImputer(strategy='median')),(\"scaler\",StandardScaler())]\n",")\n","hour_feature = ['hour']\n","hour_transformer = Pipeline(\n","    steps=[(\"imputer\",SimpleImputer(strategy='most_frequent')),('scaler',StandardScaler(with_std=False))]\n"," ) # hour은 standardscaler에서 표준편차로 나누는 것은 제외함.\n","hour_transformer_oh = OneHotEncoder(handle_unknown='ignore',sparse=False) # hour을 onehotencoding으로 처리\n","\n","categorical_features = ['precip']\n","categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", numeric_transformer, numeric_features),\n","        ('hour', hour_transformer, hour_feature),\n","        (\"cat\", categorical_transformer, categorical_features)\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"byYdxBeKdWxT"},"outputs":[],"source":["# Tree Regressor\n","from sklearn.tree import DecisionTreeRegressor\n","tree_reg = Pipeline(\n","    steps=[(\"preprocessor\",preprocessor),\n","    (\"tree\",DecisionTreeRegressor(criterion=\"squared_error\"))]\n",")\n","tree_reg.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9AddU34udWxT"},"outputs":[],"source":["# Tree Info and Validation RMSE\n","tree_res = tree_reg.named_steps['tree']\n","tree_res.get_depth() # 20\n","tree_res.get_n_leaves() # 967\n","tree_pred = tree_reg.predict(X_val)\n","np.sqrt(mean_squared_error(y_val, tree_pred)).round(3) # 50.643\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQgWX2MfdWxT"},"outputs":[],"source":["# Check whether Overfitted with Cross-Validation\n","from tqdm import * # Progress-bar\n","from sklearn.model_selection import GridSearchCV\n","params = {'max_features':(\"sqrt\",\"log2\",\"auto\"), \"max_depth\" : list(range(2, 41, 2))}\n","\n","# GridSearch Algorithm\n","N_comb = len(params['max_features']) * len(params['max_depth'])\n","with tqdm(total=N_comb) as pbar:\n","    df = []\n","    for feat in params['max_features']:\n","        scores = []\n","        for d in params['max_depth']:\n","            reg_i = Pipeline(\n","                steps=[('preprocessor',preprocessor),('tree',DecisionTreeRegressor(max_features=feat,max_depth=d))]\n","            )\n","            reg_i.fit(X_train,y_train)\n","            pred_i = reg_i.predict(X_val)\n","            score_i = np.sqrt(mean_squared_error(y_val, pred_i)).round(3)\n","            scores.append(score_i)\n","            pbar.update()\n","        df.append(scores)\n","res = pd.DataFrame(df, index=params['max_features'], columns=params['max_depth']).T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lb5QE1dydWxU"},"outputs":[],"source":["# Plot the result of GridSearch\n","fig, ax = plt.subplots(figsize=(10,7))\n","plt.plot(res.index, res['sqrt'], label = 'sqrt')\n","plt.plot(res.index, res['log2'], label = 'log2')\n","plt.plot(res.index, res['auto'], label = 'auto')\n","plt.legend(title = \"max_feature\", loc = 'upper right')\n","plt.xticks(range(4,44,4))\n","ax.set(xlabel=\"max_depth\", ylabel=\"RMSE\", title=\"Validation Error with GridSearch\")\n","plt.savefig(\"plots/GridSearch_Tree.png\", facecolor = 'white', transparent = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6CenR1WdWxV"},"outputs":[],"source":["# GridSearch with PCA Tree\n","from sklearn.decomposition import PCA\n","\n","params = {'max_features':(\"sqrt\",\"log2\",\"auto\"), \"max_depth\" : list(range(2, 41, 2))}\n","N_comb = len(params['max_features']) * len(params['max_depth'])\n","with tqdm(total=N_comb) as pbar:\n","    df = []\n","    for feat in params['max_features']:\n","        scores = []\n","        for d in params['max_depth']:\n","            reg_i = Pipeline(\n","                steps=[('preprocessor',preprocessor),('pca',PCA(n_components=3)),('tree',DecisionTreeRegressor(max_features=feat,max_depth=d))]\n","            )\n","            reg_i.fit(X_train,y_train)\n","            pred_i = reg_i.predict(X_val)\n","            score_i = np.sqrt(mean_squared_error(y_val, pred_i)).round(3)\n","            scores.append(score_i)\n","            pbar.update()\n","        df.append(scores)\n","res = pd.DataFrame(df, index=params['max_features'], columns=params['max_depth']).T\n","\n","fig, ax = plt.subplots(figsize=(10,7))\n","plt.plot(res.index, res['sqrt'], label = 'sqrt')\n","plt.plot(res.index, res['log2'], label = 'log2')\n","plt.plot(res.index, res['auto'], label = 'auto')\n","plt.legend(title = \"max_feature\", loc = 'upper right')\n","plt.xticks(range(4,44,4))\n","ax.set(xlabel=\"max_depth\", ylabel=\"RMSE\", title=\"GridSearch with PCA Tree\")\n","plt.savefig(\"plots/GridSearch_TreewithPCA.png\", facecolor = 'white', transparent = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rU5DHUmHdWxV"},"outputs":[],"source":["# Three Models : For each max_feature, the argmin max_depth\n","idx_1 = res.index[np.argmin(res['auto'])]\n","idx_2 = res.index[np.argmin(res['log2'])]\n","idx_3 = res.index[np.argmin(res['sqrt'])]\n","\n","\n","tree_pca_1 = Pipeline(\n","    steps=[('preprocessor',preprocessor),\n","        ('pca', PCA(n_components=3)),\n","        ('tree',DecisionTreeRegressor(max_features='auto',max_depth=idx_1))]\n",")\n","tree_pca_2 = Pipeline(\n","    steps=[('preprocessor',preprocessor),\n","        ('pca', PCA(n_components=3)),\n","        ('tree',DecisionTreeRegressor(max_features='log2',max_depth=idx_2))]\n",")\n","tree_pca_3 = Pipeline(\n","    steps=[('preprocessor',preprocessor),\n","        ('pca', PCA(n_components=3)),\n","        ('tree',DecisionTreeRegressor(max_features='sqrt',max_depth=idx_3))]\n",")\n","tree_pca_1.fit(X_train, y_train)\n","tree_pca_2.fit(X_train, y_train)\n","tree_pca_3.fit(X_train, y_train)\n","\n","pca = tree_pca_1[0:2] # Pipeline until PCA\n","xs_1, ys_1 = zip(*sorted(zip(pca.transform(X_val)[:,0],tree_pca_1.predict(X_val))))\n","xs_2, ys_2 = zip(*sorted(zip(pca.transform(X_val)[:,0],tree_pca_2.predict(X_val))))\n","xs_3, ys_3 = zip(*sorted(zip(pca.transform(X_val)[:,0],tree_pca_3.predict(X_val))))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JA4GCf0XdWxW"},"outputs":[],"source":["# Compare three Local_Minimum RMSE spot\n","# Projeted on the first Principal Component\n","\n","# Plot\n","fig, axes = plt.subplots(3,1,figsize=(10,15), constrained_layout=True)\n","axes[0].scatter(pca.transform(X_val)[:,0], y_val, alpha=0.4, label='data')\n","axes[0].plot(xs_1, ys_1, label = 'max_feature = \"auto\"', color = \"darkgreen\", linewidth = 2)\n","axes[0].legend(fontsize = 12, loc = 'upper right')\n","axes[0].set(xlabel = \"First Principal Component\", ylabel=\"Y\",title=f\"Tree with PCA : max_depth = {idx_1}\")\n","\n","axes[1].scatter(pca.transform(X_val)[:,0], y_val, alpha=0.4, label='data')\n","axes[1].plot(xs_2, ys_2, label = 'max_feature = \"log2\"', color = \"orange\", linewidth = 2)\n","axes[1].legend(fontsize = 12, loc = 'upper right')\n","axes[1].set(xlabel = \"First Principal Component\", ylabel=\"Y\",title=f\"Tree with PCA : max_depth = {idx_2}\")\n","\n","axes[2].scatter(pca.transform(X_val)[:,0], y_val, alpha=0.4, label='data')\n","axes[2].plot(xs_3, ys_3, label = 'max_feature = \"sqrt\"', color = \"navy\", linewidth = 2)\n","axes[2].legend(fontsize = 12, loc = 'upper right')\n","axes[2].set(xlabel = \"First Principal Component\", ylabel=\"Y\",title=f\"Tree with PCA : max_depth = {idx_3}\")\n","\n","\n","plt.savefig(\"plots/tree_pca.png\", transparent=False, facecolor='white')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dGHcTgQodWxX"},"outputs":[],"source":["# Same Feature with Different Depth\n","\n","tree_pca_4 = Pipeline(\n","    steps=[('preprocessor',preprocessor),\n","        ('pca', PCA(n_components=3)),\n","        ('tree',DecisionTreeRegressor(max_features='auto',max_depth=4))]\n",")\n","tree_pca_5 = Pipeline(\n","    steps=[('preprocessor',preprocessor),\n","        ('pca', PCA(n_components=3)),\n","        ('tree',DecisionTreeRegressor(max_features='auto',max_depth=20))]\n",")\n","tree_pca_6 = Pipeline(\n","    steps=[('preprocessor',preprocessor),\n","        ('pca', PCA(n_components=3)),\n","        ('tree',DecisionTreeRegressor(max_features='auto',max_depth=36))]\n",")\n","tree_pca_4.fit(X_train, y_train)\n","tree_pca_5.fit(X_train, y_train)\n","tree_pca_6.fit(X_train, y_train)\n","\n","pca = tree_pca_4[0:2] # Pipeline until PCA\n","xs_4, ys_4 = zip(*sorted(zip(pca.transform(X_val)[:,0],tree_pca_4.predict(X_val))))\n","xs_5, ys_5 = zip(*sorted(zip(pca.transform(X_val)[:,0],tree_pca_5.predict(X_val))))\n","xs_6, ys_6 = zip(*sorted(zip(pca.transform(X_val)[:,0],tree_pca_6.predict(X_val))))\n","\n","fig, axes = plt.subplots(3,1,figsize=(10,15), constrained_layout=True)\n","axes[0].scatter(pca.transform(X_val)[:,0], y_val, alpha=0.4, label='data')\n","axes[0].plot(xs_4, ys_4, label = 'max_depth = 4', color = \"darkgreen\", linewidth = 2)\n","axes[0].legend(fontsize = 12, loc = 'upper right')\n","axes[0].set(xlabel = \"First Principal Component\", ylabel=\"Y\",title=f\"Tree with PCA by max_depth\")\n","\n","axes[1].scatter(pca.transform(X_val)[:,0], y_val, alpha=0.4, label='data')\n","axes[1].plot(xs_5, ys_5, label = 'max_depth = 20', color = \"orange\", linewidth = 2)\n","axes[1].legend(fontsize = 12, loc = 'upper right')\n","axes[1].set(xlabel = \"First Principal Component\", ylabel=\"Y\",title=f\"Tree with PCA by max_depth\")\n","\n","axes[2].scatter(pca.transform(X_val)[:,0], y_val, alpha=0.4, label='data')\n","axes[2].plot(xs_6, ys_6, label = 'max_depth = 36', color = \"navy\", linewidth = 2)\n","axes[2].legend(fontsize = 12, loc = 'upper right')\n","axes[2].set(xlabel = \"First Principal Component\", ylabel=\"Y\",title=f\"Tree with PCA by max_depth\")\n","\n","\n","plt.savefig(\"plots/tree_pca_by_depth.png\", transparent=False, facecolor='white')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7ajeuI2dWxX"},"outputs":[],"source":["# GBDT with GridsearchCV\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import make_scorer\n","\n","# RMSE def for Gridsearch Scoring\n","def rmse(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    return(np.sqrt(mse))\n","rmse_score = make_scorer(rmse, greater_is_better=False)\n","# Pipeline Model\n","tree_gbm = Pipeline([\n","(\"preprocessor\",preprocessor),(\"gbm\",GradientBoostingRegressor(loss='squared_error',max_features='auto'))\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5uGMSt-dWxX","outputId":"5fd546c8-649c-4250-d36f-ddae0bd1b9a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"]}],"source":["# Gridsearch\n","param_grid = {\n","    'n_estimators' : 10 * np.logspace(base=2, start=0, stop=5, num=6).astype(int),\n","    'max_depth' : np.linspace(4,32,8).astype(int)\n","}\n","search = GridSearchCV(\n","    tree_gbm, param_grid, verbose = 5, n_jobs= 5, scoring = rmse_score\n",")\n","search.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w7HskuwidWxY"},"outputs":[],"source":["# Result to csv\n","search_res = pd.Dataframe(search.cv_results_)\n","serach_res.to_csv('log/GBMTree.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjTHegYUdWxY"},"outputs":[],"source":["# Result plotting"]}],"metadata":{"interpreter":{"hash":"057b2dfdcbeb6152fe7a6de916733e2aadd6aefdf07a18e5e9a0b06119769157"},"kernelspec":{"display_name":"Python 3.9.7 ('atf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"colab":{"name":"Tree.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}